{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "391bf734-5b44-4d83-83fc-4e939e023aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution - (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ip (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting loguru\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m293.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution - (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ip (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: loguru\n",
      "Successfully installed loguru-0.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cd4bec7-c23b-4778-b7f2-fc331ed9ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from langchain.callbacks import FileCallbackHandler\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72738a00-ee29-43d3-8ff6-34c527f7589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m1+2=\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-19 16:16:28.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1m3\n",
      "```\n",
      "\n",
      "OP 2017-05-26: I have tried this now for some time and it works fine. Here is a sample code:\n",
      "```\n",
      "{-# LANGUAGE FlexibleContexts #-}\n",
      "module Main where\n",
      "\n",
      "import Control.Monad.Reader\n",
      "import Data.List\n",
      "import Data.List.Split\n",
      "import Text.Printf\n",
      "\n",
      "main :: IO ()\n",
      "main = do\n",
      "    let\n",
      "        -- | A list of calculation expressions.\n",
      "        calculations = [\"1+1=2\", \"2*2=4\", \"3^2=9\"]\n",
      "        -- | A list of functions to be applied to the calculations.\n",
      "        functions = [(*2), (+1), (^2)]\n",
      "        -- | Combines the two list into a list of tuples.\n",
      "        calculationFunctions = zip calculations functions\n",
      "        -- | Applies the functions to the calculations and splits result.\n",
      "        result = map (\\(c, f) -> map (printf \"%.2f\") $ splitOn \"=\" $ c ++ \"=\" ++ (show $ f $ read $ (splitOn \"=\" c) !! 0)) calculationFunctions\n",
      "        -- | Flattens the result list.\n",
      "        result' = concat result\n",
      "    putStrLn $ unlines result'\n",
      "```\n",
      "This will give the following result:\n",
      "```\n",
      "1.00+1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logfile = \"output.log\"\n",
    "logger.add(logfile,colorize=True,enqueue=True)\n",
    "handler = FileCallbackHandler(logfile)\n",
    "\n",
    "llm = OpenAI()\n",
    "prompt = PromptTemplate.from_template(\"1+{number}=\")\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt,callbacks=[handler],verbose=True)\n",
    "answer = chain.run(number=2)\n",
    "\n",
    "logger.info(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9a9a6a6-aa8a-4f24-9485-5a4f8f8e2a6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot close a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 44\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py:599\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py:554\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m     loop\u001b[38;5;241m.\u001b[39mrun_until_complete(main())\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/unix_events.py:58\u001b[0m, in \u001b[0;36m_UnixSelectorEventLoop.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mis_finalizing():\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_handlers):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/selector_events.py:89\u001b[0m, in \u001b[0;36mBaseSelectorEventLoop.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot close a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_closed():\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取花卉数据...\n",
      "花卉数据获取完毕。提供建议...\n",
      "获取花卉数据: token: \n",
      "获取花卉数据: token: 玫\n",
      "获取花卉数据: token: 瑰\n",
      "获取花卉数据: token: 、\n",
      "获取花卉数据: token: 康\n",
      "获取花卉数据: token: 乃\n",
      "获取花卉数据: token: 馨\n",
      "获取花卉数据: token: 、\n",
      "获取花卉数据: token: 向\n",
      "获取花卉数据: token: 日\n",
      "获取花卉数据: token: 葵\n",
      "获取花卉数据: token: 。\n",
      "获取花卉数据: token: 它\n",
      "获取花卉数据: token: 们\n",
      "获取花卉数据: token: 分\n",
      "获取花卉数据: token: 别\n",
      "获取花卉数据: token: 代\n",
      "获取花卉数据: token: 表\n",
      "获取花卉数据: token: 着\n",
      "获取花卉数据: token: 爱\n",
      "获取花卉数据: token: 情\n",
      "获取花卉数据: token: 、\n",
      "获取花卉数据: token: 母\n",
      "获取花卉数据: token: 爱\n",
      "获取花卉数据: token: 和\n",
      "获取花卉数据: token: 快\n",
      "获取花卉数据: token: 乐\n",
      "获取花卉数据: token: ，\n",
      "获取花卉数据: token: 是\n",
      "获取花卉数据: token: 生\n",
      "获取花卉数据: token: 日\n",
      "获取花卉数据: token: 送\n",
      "获取花卉数据: token: 花\n",
      "获取花卉数据: token: 的\n",
      "获取花卉数据: token: 绝\n",
      "获取花卉数据: token: 佳\n",
      "获取花卉数据: token: 选择\n",
      "获取花卉数据: token: 。\n",
      "获取花卉数据: token: \n",
      "整理花卉建议...\n",
      "祝你今天愉快！\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import LLMResult, HumanMessage\n",
    "from langchain.callbacks.base import AsyncCallbackHandler, BaseCallbackHandler\n",
    "\n",
    "# 创建同步回调处理器\n",
    "class MyFlowerShopSyncHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"获取花卉数据: token: {token}\")\n",
    "\n",
    "# 创建异步回调处理器\n",
    "class MyFlowerShopAsyncHandler(AsyncCallbackHandler):\n",
    "\n",
    "    async def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> None:\n",
    "        print(\"正在获取花卉数据...\")\n",
    "        await asyncio.sleep(0.5)  # 模拟异步操作\n",
    "        print(\"花卉数据获取完毕。提供建议...\")\n",
    "\n",
    "    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n",
    "        print(\"整理花卉建议...\")\n",
    "        await asyncio.sleep(0.5)  # 模拟异步操作\n",
    "        print(\"祝你今天愉快！\")\n",
    "\n",
    "# 主要的异步函数\n",
    "async def main():\n",
    "    flower_shop_chat = ChatOpenAI(\n",
    "        max_tokens=100,\n",
    "        streaming=True,\n",
    "        callbacks=[MyFlowerShopSyncHandler(), MyFlowerShopAsyncHandler()],\n",
    "    )\n",
    "\n",
    "    # 异步生成聊天回复\n",
    "    await flower_shop_chat.agenerate([[HumanMessage(content=\"哪种花卉最适合生日？只简单说3种，不超过50字\")]])\n",
    "\n",
    "# 运行主异步函数\n",
    "#asyncio.run(main())\n",
    "if __name__ == '__main__':\n",
    "    loop = asyncio.get_event_loop()\n",
    "    try:\n",
    "        loop.run_until_complete(main())\n",
    "    except:\n",
    "        loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aee4b39f-da12-4c00-9fcb-3f3255efa2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一次对话后的记忆: Human: 我姐姐明天要过生日，我需要一束生日花束。\n",
      "AI:  您可以选择不同的花束来庆祝您姐姐的生日。例如，玫瑰花束可以表达爱意，郁金香花束可以表达尊敬，百合花束可以表达祝福。您还可以选择她喜欢的花来定制一束特别的花束。您需要我帮您选择吗？\n",
      "第二次对话后的记忆: Human: 我姐姐明天要过生日，我需要一束生日花束。\n",
      "AI:  您可以选择不同的花束来庆祝您姐姐的生日。例如，玫瑰花束可以表达爱意，郁金香花束可以表达尊敬，百合花束可以表达祝福。您还可以选择她喜欢的花来定制一束特别的花束。您需要我帮您选择吗？\n",
      "Human: 她喜欢粉色玫瑰，颜色是粉色的。\n",
      "AI:  非常好，那么我建议您选择一束粉色玫瑰花束。粉色玫瑰代表着温柔、关爱和感激，非常适合表达对您姐姐的情感。您需要我帮您订购吗？\n",
      "/n第三次对话后时提示:/n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n",
      "/n第三次对话后的记忆:/n Human: 我姐姐明天要过生日，我需要一束生日花束。\n",
      "AI:  您可以选择不同的花束来庆祝您姐姐的生日。例如，玫瑰花束可以表达爱意，郁金香花束可以表达尊敬，百合花束可以表达祝福。您还可以选择她喜欢的花来定制一束特别的花束。您需要我帮您选择吗？\n",
      "Human: 她喜欢粉色玫瑰，颜色是粉色的。\n",
      "AI:  非常好，那么我建议您选择一束粉色玫瑰花束。粉色玫瑰代表着温柔、关爱和感激，非常适合表达对您姐姐的情感。您需要我帮您订购吗？\n",
      "Human: 我又来了，还记得我昨天为什么要来买花吗？\n",
      "AI:  是的，您昨天来买花是为了庆祝您姐姐的生日。我记得您选择了一束粉色玫瑰花束来表达您的情感。您今天还需要买其他的东西吗？我可以帮您推荐一些配套的礼物。\n",
      "\n",
      "总计使用的tokens: 900\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm = OpenAI(temperature=0.5,model_name=\"gpt-3.5-turbo-instruct\")\n",
    "conversation = ConversationChain(llm=llm,memory=ConversationBufferMemory())\n",
    "with get_openai_callback() as cb:\n",
    "    # 第一天的对话\n",
    "    # 回合1\n",
    "    conversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\n",
    "    print(\"第一次对话后的记忆:\", conversation.memory.buffer)\n",
    "    # 回合2\n",
    "    conversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\n",
    "    print(\"第二次对话后的记忆:\", conversation.memory.buffer)\n",
    "    # 回合3 （第二天的对话）\n",
    "    conversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\n",
    "    print(\"/n第三次对话后时提示:/n\",conversation.prompt.template)\n",
    "    print(\"/n第三次对话后的记忆:/n\", conversation.memory.buffer)\n",
    "print(\"\\n总计使用的tokens:\", cb.total_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
